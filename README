# ğŸ§‘â€ğŸ« Mentor â€“ Your Personal AI Coach

**Created by Marc Sperzel**

Mentor is a conversational AI that **remembers what matters** and guides you with direct, noâ€‘fluff advice.  
Think of it as a seasoned mentor who interviews you, learns your goals, and asks sharp followâ€‘up questions to accelerate your growth.

---

## âœ¨ Vision

1. **Longâ€‘term relationship** â€“ Mentor builds an evolving knowledge base about *you*: your goals, preferences, and past decisions.  
2. **Socratic guidance** â€“ It doesn't lecture; it probes. Mentor asks questions that surface blind spots and spark selfâ€‘reflection.  
3. **Actionable insight** â€“ Each answer is concise, specific, and backed by the context it has storedâ€”not generic selfâ€‘help jargon.  
4. **Privacy & control** â€“ All memories live in a dedicated memory layer (Mem0). You can inspect, export, or delete them at any time.

---

## ğŸ“‘ Table of Contents

- [Architecture](#-architecture)
- [Quickstart](#-quickstart)
- [Key Files](#-key-files)
- [Roadmap](#-roadmap)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ”§ Architecture

| Layer      | Tech                              | Purpose                                             |
|------------|-----------------------------------|-----------------------------------------------------|
| **UI**     | Streamlit                         | Lightweight chat frontâ€‘end with token streaming      |
| **Agent**  | `Mentor` class                    | Orchestrates retrieval â†’ LLM â†’ async store          |
| **Memory** | Mem0                              | Vector + metadata store for longâ€‘term memories       |
| **LLM**    | OpenAI GPTâ€‘4oâ€‘mini (pluggable)    | Generates and streams responses                     |

> **Flow per turn**
> 1. Retrieve top memories `k=5` (recencyâ€‘weighted, deduped)  
> 2. Inject them into the system prompt and stream the answer  
> 3. Persist the dialogue asynchronously in the background

---

## ğŸš€ Quickstart

```bash
pip install -r requirements.txt
streamlit run app.py
```

Set the following environment variables (see `.env.example`):

```env
OPENAI_API_KEY=sk-â€¦
MEM0_API_KEY=mem-â€¦
```

---

## ğŸ“š Key Files

| Path              | Description                          |
|-------------------|--------------------------------------|
| `src/mentor.py`   | Core agent logic and streaming helper |
| `src/memory.py`   | Retrieval, reâ€‘ranking, async persistence |
| `src/llm.py`      | Thin wrapper around the OpenAI client |
| `app.py`          | Streamlit UI                         |

---

## ğŸ—ºï¸ Roadmap

- **Multiâ€‘user auth** with secure perâ€‘user key management
- **Scheduled reflections**: daily/weekly checkâ€‘ins driven by stored goals
- **Voice mode** using WebRTC + Whisper realâ€‘time transcription
- **Plugin hooks** for calendar, tasks, or custom knowledge bases

---

## ğŸ¤ Contributing

1. Fork & clone the repo  
2. `pre-commit install` for linting hooks  
3. Submit a PR with a concise description; small, focused patches are easier to review!

---

## ğŸ“ License

MIT â€” see [`LICENSE`](LICENSE).

---

*Crafted with curiosity and a dash of Socratic questioning.*